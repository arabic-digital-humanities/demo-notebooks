{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "import gensim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import bidi.algorithm\n",
    "import arabic_reshaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding model for arabic\n",
    "This app allows you to visualize a list of words in a word embedding model for Arabic, mapped to two dimensions using Principal Component Analysis (PCA).\n",
    "\n",
    "The current model is the Wikipedia CBOW model from [AraVec](https://github.com/bakrianoo/aravec), see: Abu Bakr Soliman, Kareem Eisa, and Samhaa R. El-Beltagy, “AraVec: A set of Arabic Word Embedding Models for use in Arabic NLP”, in proceedings of the 3rd International Conference on Arabic Computational Linguistics (ACLing 2017), Dubai, UAE, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "def download_model(name, download_url):\n",
    "    outname = os.path.join(model_path, name)\n",
    "    \n",
    "    if not os.path.exists(outname):\n",
    "        resp = urlopen(download_url)\n",
    "        zf = zipfile.ZipFile(BytesIO(resp.read()), 'r')\n",
    "\n",
    "\n",
    "        fname = zf.namelist()[0]\n",
    "        with open(outname, 'wb') as fout:\n",
    "            fout.write(zf.read(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fiqh-norm\n",
      "fiqh\n",
      "fiqh-stemmed\n"
     ]
    }
   ],
   "source": [
    "model_urls = {\n",
    "    'fiqh-norm': 'https://surfdrive.surf.nl/files/index.php/s/MpDn5ckasu33LuT/download',\n",
    "    'fiqh': 'https://surfdrive.surf.nl/files/index.php/s/7RvP2iYCOXkcWRp/download',\n",
    "    'fiqh-stemmed': 'https://surfdrive.surf.nl/files/index.php/s/Ah9HeEg8vDMzPIo/download',\n",
    "    #'wiki_cbow_100': 'https://archive.org/download/aravec2.0/wiki_cbow_100.zip'\n",
    "}\n",
    "\n",
    "for name in model_urls:\n",
    "    print(name)\n",
    "    download_model(name, model_urls[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To do: list multiple available models and only download them when needed\n",
    "models = {}\n",
    "filenames = os.listdir(model_path)\n",
    "for fn in filenames:\n",
    "    try:\n",
    "        models[fn] = gensim.models.KeyedVectors.load(os.path.join(model_path, fn))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nicer_names_dict = {'wikipedia_cbow_100': 'Wikipedia',\n",
    "                    'cbow-fiqh-100-wikipedia-finetuned-wv': 'Wikipedia+Fiqh',\n",
    "                   'fiqh-i10-s100-w5-sg0_wv': 'Fiqh', \n",
    "                   'stemmed-fiqh-i10-s100-w5-sg0_wv': 'Stemmed Fiqh'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {nicer_names_dict.get(model, model): models[model] for model in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(word, model, topn=10):\n",
    "    res = model.wv.most_similar(word, topn=topn)\n",
    "    output = [u'{} \\t{:.3f}'.format(w, s) for w, s in res]\n",
    "    return '\\n'.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_embedding(word_list, model, method='pca', learning_rate=60, colors=None):\n",
    "    X = model[word_list]\n",
    "    if method is 'pca':\n",
    "        X_embedded = PCA(n_components=2).fit_transform(X)\n",
    "    else:\n",
    "        X_pre = PCA(n_components=30).fit_transform(X)\n",
    "        X_embedded = TSNE(n_components=2, learning_rate=learning_rate, random_state=0).fit_transform(X_pre)\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.scatter(X_embedded[:,0], X_embedded[:,1], c=colors)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i, w in enumerate(word_list):\n",
    "        display_word = bidi.algorithm.get_display(arabic_reshaper.reshape(w))\n",
    "        plt.annotate(display_word, xy=(X_embedded[i, 0], X_embedded[i, 1]), fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_closest_words(word, model, method='pca', topn=30, learning_rate=60, colors=None):\n",
    "    word_list = [w for w, s in model.wv.most_similar(word, topn=topn)]\n",
    "    word_list.append(word)\n",
    "    plot_embedding(word_list, model, method, learning_rate, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_widget(model_name, word_list_input, color_list_input):\n",
    "    model=models[model_name]\n",
    "    word_list = word_list_input.split('\\n')\n",
    "    word_list = [w.strip() for w in word_list]\n",
    "    word_list = [w for w in word_list if w!='' ]\n",
    "    \n",
    "    color_list = [c.strip() for c in color_list_input.split('\\n')]\n",
    "    color_list = [c for c in color_list if c!='']\n",
    "    if len(word_list) > 1:\n",
    "        try:\n",
    "            colors = None\n",
    "            if len(color_list)==len(word_list):\n",
    "                colors = color_list\n",
    "            elif len(color_list)>0:\n",
    "                print('nr of colors should match nr of words')\n",
    "            plot_embedding(word_list, model, colors=colors)\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "    elif len(word_list)==1:\n",
    "        print('Need at least two words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f5d37204764c9b9bf8714a2a9b2989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Model:', options=('fiqh-stemmed',), value='fiqh-stemmed'), HBox(children=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "input_word_list = widgets.Textarea(description='Word list:', rows=10)\n",
    "input_colors = widgets.Textarea(description='colors:', rows=10)\n",
    "input_model = widgets.Dropdown(description='Model:', options=models.keys())\n",
    "\n",
    "def update_plot(button):\n",
    "    with(out):\n",
    "        clear_output()\n",
    "        plot_widget(input_model.value, input_word_list.value, input_colors.value)\n",
    "        widgets.interaction.show_inline_matplotlib_plots()\n",
    "\n",
    "button_submit = widgets.Button(description='Submit')\n",
    "button_submit.on_click(update_plot)\n",
    "\n",
    "#button_submit = widgets.Button(description='Submit')\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "\n",
    "widgets.VBox([input_model, \n",
    "              widgets.HBox([input_word_list, input_colors]),\n",
    "              button_submit,\n",
    "              out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:adh]",
   "language": "python",
   "name": "conda-env-adh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
