{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding model for arabic\n",
    "This app allows you to find related words in a word embedding model for Arabic.\n",
    "\n",
    "The current model is the Wikipedia CBOW model from [AraVec](https://github.com/bakrianoo/aravec), see: Abu Bakr Soliman, Kareem Eisa, and Samhaa R. El-Beltagy, “AraVec: A set of Arabic Word Embedding Models for use in Arabic NLP”, in proceedings of the 3rd International Conference on Arabic Computational Linguistics (ACLing 2017), Dubai, UAE, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "def download_model(name, download_url):\n",
    "    outname = os.path.join(model_path, name)\n",
    "    \n",
    "    if not os.path.exists(outname):\n",
    "        resp = urlopen(download_url)\n",
    "        zf = zipfile.ZipFile(BytesIO(resp.read()), 'r')\n",
    "\n",
    "\n",
    "        fname = zf.namelist()[0]\n",
    "        with open(outname, 'wb') as fout:\n",
    "            fout.write(zf.read(fname))\n",
    "            \n",
    "            \n",
    "model_urls = {\n",
    "    'fiqh-norm': 'https://surfdrive.surf.nl/files/index.php/s/MpDn5ckasu33LuT/download',\n",
    "    'fiqh': 'https://surfdrive.surf.nl/files/index.php/s/7RvP2iYCOXkcWRp/download',\n",
    "    'fiqh-stemmed': 'https://surfdrive.surf.nl/files/index.php/s/Ah9HeEg8vDMzPIo/download',\n",
    "    #'wiki_cbow_100': 'https://archive.org/download/aravec2.0/wiki_cbow_100.zip'\n",
    "}\n",
    "\n",
    "for name in model_urls:\n",
    "    print(name)\n",
    "    download_model(name, model_urls[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To do: list multiple available models and only download them when needed\n",
    "models = {}\n",
    "filenames = os.listdir(model_path)\n",
    "for fn in filenames:\n",
    "    try:\n",
    "        models[fn] = gensim.models.KeyedVectors.load(os.path.join(model_path, fn))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nicer_names_dict = {'wikipedia_cbow_100': 'Wikipedia',\n",
    "                    'cbow-fiqh-100-wikipedia-finetuned-wv': 'Wikipedia+Fiqh',\n",
    "                   'fiqh-i10-s100-w5-sg0_wv': 'Fiqh', \n",
    "                   'stemmed-fiqh-i10-s100-w5-sg0_wv': 'Stemmed Fiqh'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {nicer_names_dict.get(model, model): models[model] for model in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(word, model, topn=10):\n",
    "    res = model.wv.most_similar(word, topn=topn)\n",
    "    output = [u'{} \\t{:.3f}'.format(w, s) for w, s in res]\n",
    "    return '\\n'.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e812ddb7f1e94e519f61744b0b2a0215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Word:'), IntSlider(value=50, description='Number of results:', min=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = {model: widgets.Textarea(disabled=True, rows=30, description=model )\n",
    "                                   for model in models}\n",
    "\n",
    "def print_related_words(button):\n",
    "    for model in models:\n",
    "        try: \n",
    "            outputs[model].value = most_similar(input_word.value.strip(), models[model], input_number.value)\n",
    "        except KeyError:\n",
    "            outputs[model].value = 'Error: word does not exist in vocabulary'\n",
    "#     except:\n",
    "#         output.value = 'Unknown error'\n",
    "\n",
    "input_word = widgets.Text(description='Word:')\n",
    "input_number = widgets.IntSlider(\n",
    "    value=50,\n",
    "    min=5,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description='Number of results:',\n",
    ")\n",
    "\n",
    "button_submit = widgets.Button(description='Submit')\n",
    "button_submit.on_click(print_related_words)\n",
    "\n",
    "output_boxes = tuple([outputs[m] for m in sorted(outputs.keys())])\n",
    "widgets.VBox((input_word, input_number, button_submit, widgets.HBox(output_boxes)))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:adh]",
   "language": "python",
   "name": "conda-env-adh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
